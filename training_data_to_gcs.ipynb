{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/waymo_open_dataset/utils/range_image_utils.py:59: The name tf.unsorted_segment_max is deprecated. Please use tf.math.unsorted_segment_max instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/waymo_open_dataset/utils/range_image_utils.py:226: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "from google.cloud import storage\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from object_detection.utils import dataset_util\n",
    "from waymo_open_dataset import label_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'waymo_validation'\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(frame,count):\n",
    "  # TODO(user): Populate the following variables from your example.\n",
    "  center_x = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "  center_y = [] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  width = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "  height = [] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "  classes = [] # List of integer class id of bounding box (1 per box)\n",
    "  \n",
    "  filename = bytes(('waymo_training_front_'+str(count)+'.jpg'), 'utf-8') # Filename of the image. Empty if image is not from file\n",
    "  #row = []\n",
    "  \n",
    "  for camera_image in frame.images:\n",
    "    if camera_image.name == 1:\n",
    "      #row.append(filename.decode('utf-8'))\n",
    "      encoded_image_data = camera_image.image\n",
    "      #img_writer = open('validation_dataset/images/'+filename.decode('utf-8'),'wb')\n",
    "      #img_writer.write(encoded_image_data)\n",
    "      \n",
    "      #blob = bucket.blob('validation_dataset/images/'+filename.decode('utf-8'))\n",
    "\n",
    "      #blob.upload_from_string(encoded_image_data,content_type='image/png')\n",
    "      \n",
    "      #img_writer.close()\n",
    "      break\n",
    "  for camera_labels in frame.camera_labels:\n",
    "    if camera_labels.name == 1:\n",
    "      for label in camera_labels.labels:\n",
    "        if label.type == label_pb2.Label.Type.TYPE_VEHICLE or label.type == label_pb2.Label.Type.TYPE_PEDESTRIAN:\n",
    "\n",
    "          center_x.append(label.box.center_x)\n",
    "          center_y.append(label.box.center_y)\n",
    "          width.append(label.box.length)\n",
    "          height.append(label.box.width)\n",
    "            \n",
    "#           x_min = label.box.center_x - 0.5 * label.box.length\n",
    "#           y_min = label.box.center_y - 0.5 * label.box.width\n",
    "#           x_max = label.box.center_x + 0.5 * label.box.length\n",
    "#           y_max = label.box.center_y + 0.5 * label.box.width\n",
    "            \n",
    "          if label.type == label_pb2.Label.Type.TYPE_VEHICLE:\n",
    "            classes.append(0)\n",
    "            classes_text.append(b\"vehicle\")\n",
    "            label = 0\n",
    "            \n",
    "          else:\n",
    "            classes.append(1)\n",
    "            classes_text.append(b\"pedestrian\")\n",
    "            label = 1\n",
    "#           row.append(x_min)\n",
    "#           row.append(y_min)\n",
    "#           row.append(x_max)\n",
    "#           row.append(y_max)\n",
    "#           row.append(label)\n",
    "        \n",
    "            \n",
    "#          row = row + ',' + str(x_min) + ',' + str(y_min) + ',' + str(x_max) + ',' + str(y_max) + ',' + str(label)\n",
    "\n",
    "\n",
    "  #print(encoded_image_data)  \n",
    "\n",
    "  image_format = b'jpeg'\n",
    "  #plt.imshow(tf.image.decode_jpeg(encoded_image_data), cmap=None)\n",
    " # print(dataset_util.bytes_feature(tf.image.decode_jpeg(encoded_image_data)))  \n",
    " \n",
    "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/filename': dataset_util.bytes_feature(filename),\n",
    "      'image/format': dataset_util.bytes_feature(image_format),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "      'image/object/bbox/center_x': dataset_util.float_list_feature(center_x),\n",
    "      'image/object/bbox/center_y': dataset_util.float_list_feature(center_y),\n",
    "      'image/object/bbox/width': dataset_util.float_list_feature(width),\n",
    "      'image/object/bbox/height': dataset_util.float_list_feature(height),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }))\n",
    "  #csv_writer.writerow(row)\n",
    "  return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"image_feature_description={\n",
    "      'image/filename': tf.io.VarLenFeature(tf.string),\n",
    "      'image/format': tf.io.FixedLenFeature([],tf.string),\n",
    "      'image/encoded': tf.io.FixedLenFeature([],tf.string),\n",
    "      'image/object/bbox/center_x': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/center_y': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/width': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/height': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "      'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "  }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.join('data/', f) for f in os.listdir('data/') if 'tfrecord' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4764"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAME = filenames\n",
    "#FILENAME = 'data/segment-10448102132863604198_472_000_492_000_with_camera_labels.tfrecord'\n",
    "#csvFile = open('validation_dataset/csv_files/validation_annotation.csv', 'w')\n",
    "#csv_writer = csv.writer(csvFile)\n",
    "#writer.writerow(row)   \n",
    "    \n",
    "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
    "count = 1\n",
    "frame = open_dataset.Frame()\n",
    "file_count = 24\n",
    "record_file = 'gs://waymo_validation/Training_data/tf_records/waymo_images.tfrecords'\n",
    "writer = tf.python_io.TFRecordWriter(record_file+str(file_count).zfill(5))\n",
    "for data in dataset:\n",
    "    if count % 200 == 0:\n",
    "        writer.close()\n",
    "        file_count += 1\n",
    "        writer = tf.python_io.TFRecordWriter(record_file+str(file_count).zfill(5))\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    example = create_tf_example(frame,count)\n",
    "    writer.write(example.SerializeToString())\n",
    "    count += 1\n",
    "    \n",
    "    #print(example)\n",
    "    #if count == 3:\n",
    "    \n",
    "\n",
    "writer.close()\n",
    "#csvFile.close()\n",
    "print(file_count)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_record_files = [os.path.join('validation_dataset/', f) for f in os.listdir('validation_dataset/') if 'tfrecord' in f]\n",
    "\n",
    "def _parse_function(proto):\n",
    "    # define your tfrecord again. Remember that you saved your image as a string.\n",
    "    image_feature_description={\n",
    "      'image/filename': tf.io.VarLenFeature(tf.string),\n",
    "      'image/format': tf.io.FixedLenFeature([],tf.string),\n",
    "      'image/encoded': tf.io.FixedLenFeature([],tf.string),\n",
    "      'image/object/bbox/center_x': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/center_y': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/width': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/height': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "      'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "  }\n",
    "    # Load one example\n",
    "    parsed_features = tf.parse_single_example(proto, image_feature_description)\n",
    "    \n",
    "    # Turn your saved image string into an array\n",
    "    # parsed_features['image/encoded'] = tf.decode_raw(\n",
    "    #     parsed_features['image/encoded'], tf.uint8)\n",
    "    parsed_features['image/encoded'] = tf.io.decode_jpeg(\n",
    "    parsed_features['image/encoded'])\n",
    "    \n",
    "    return parsed_features['image/encoded'], parsed_features[\"image/object/class/text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1280, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "#dataset = tf.data.TFRecordDataset(input_record_files)\n",
    "dataset = ds_train\n",
    "# Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "dataset = dataset.map(_parse_function, num_parallel_calls=8)\n",
    "\n",
    "# This dataset will go on forever\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Set the number of datapoints you want to load and shuffle \n",
    "dataset = dataset.shuffle(3)\n",
    "\n",
    "# Set the batchsize\n",
    "dataset = dataset.batch(8)\n",
    "\n",
    "# Create an iterator\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Create your tf representation of the iterator\n",
    "image, label = iterator.get_next()\n",
    "# Bring your picture back in shape\n",
    "\n",
    "print(image.shape)\n",
    "#print(image)\n",
    "\n",
    "\n",
    "#image = tf.reshape(image, [-1, 1280, 1920, 3])\n",
    "#print(image)\n",
    "# Create a one hot array for your labels\n",
    "#label = tf.one_hot(label, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\t\t     waymo_images.tfrecords00012\n",
      "waymo_images.tfrecords00000  waymo_images.tfrecords00013\n",
      "waymo_images.tfrecords00001  waymo_images.tfrecords00014\n",
      "waymo_images.tfrecords00002  waymo_images.tfrecords00015\n",
      "waymo_images.tfrecords00003  waymo_images.tfrecords00016\n",
      "waymo_images.tfrecords00004  waymo_images.tfrecords00017\n",
      "waymo_images.tfrecords00005  waymo_images.tfrecords00018\n",
      "waymo_images.tfrecords00006  waymo_images.tfrecords00019\n",
      "waymo_images.tfrecords00007  waymo_images.tfrecords00020\n",
      "waymo_images.tfrecords00008  waymo_images.tfrecords00021\n",
      "waymo_images.tfrecords00009  waymo_images.tfrecords00022\n",
      "waymo_images.tfrecords00010  waymo_images.tfrecords00023\n",
      "waymo_images.tfrecords00011  waymo_images.tfrecords00024\n"
     ]
    }
   ],
   "source": [
    "!ls validation_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.TFRecordDataset('gs://waymo_validation/validation_dataset/waymo_images.tfrecords00000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gs://waymo_validation/validation_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f823c9369afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gs://waymo_validation/validation_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gs://waymo_validation/validation_dataset'"
     ]
    }
   ],
   "source": [
    "os.listdir('gs://waymo_validation/validation_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
